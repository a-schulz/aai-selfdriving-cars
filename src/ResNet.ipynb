{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Code from https://www.kaggle.com/code/mohamedmagdy191/traffic-signs-recognition-resnet-from-scratch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cef57aaf3d0b33b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet Explained\n",
    "\n",
    "**ResNet is a type of CNN.It was designed to tackle the issue of vanishing gradients in deep networks, which was a major hindrance in developing deep neural networks. Its architecture enables the network to learn multiple layers of features without getting stuck in local minima.**\n",
    "\n",
    "### Here are the key features of the ResNet (Residual Network) architecture:\n",
    "\n",
    "* Residual Connections: ResNet incorporates residual connections, which allow for training very deep neural networks and alleviate the vanishing gradient problem. \n",
    "\n",
    "* Identity Mapping: ResNet uses identity mapping as the residual function, which makes the training process easier by learning the residual mapping rather than the actual mapping.\n",
    "\n",
    "* Depth: ResNet enables the creation of very deep neural networks, which can improve performance on image recognition tasks. \n",
    "\n",
    "* Fewer Parameters: ResNet achieves better results with fewer parameters, making it computationally more efficient.\n",
    "\n",
    "* State-of-the-art Results: ResNet has achieved state-of-the-art results on various image recognition tasks and has become a widely used benchmark for image recognition tasks.\n",
    "\n",
    "* General and Effective Approach: The authors conclude that residual connections are a general and effective approach for enabling deeper networks.\n",
    "\n",
    "### How ResNet Works?\n",
    "\n",
    "* ResNet works by adding residual connections to the network, which helps to maintain the information flow throughout the network and prevents the gradients from vanishing.\n",
    "\n",
    "* The residual connection is a shortcut that allows the information to bypass one or more layers in the network and reach the output directly.\n",
    "\n",
    "* The residual connection allows the network to learn the residual function and make small updates to the parameters, which enables the network to converge faster and achieve better performance.\n",
    "\n",
    "* This enables the network to learn residual functions and helps the network to converge faster and achieve better performance.\n",
    "\n",
    "* The residual connection is based on the idea that instead of trying to learn the complex mapping between the inputs and the outputs, it is easier to learn the residual function, which maps the inputs to the desired outputs.\n",
    "\n",
    "### The Problem Statement\n",
    "Deep Neural Networks provide more accuracy as the number of layers increases. But, when we go deeper into the network, the accuracy of the network decreases instead of increasing. An increase in the depth of the network increases the training error, which ultimately increases the test error. Because of this, the network cannot generalize well for new data, which becomes inefficient. This degradation indicates that the increase in the model layer does not aid the modelâ€™s performance.\n",
    "\n",
    "### The solution\n",
    "Adding more layers to a suitably deep model leads to higher training errors. The paper presents how architectural changes like residual learning tackle this degradation problem using residual networks. Residual Network adds an identity mapping between the layers. Applying identity mapping to the input will give the output the same as the input. The skip connections directly pass the input to the output, effectively allowing the network to learn an identity function. The paper presents a deep convolutional neural network architecture that solves the vanishing gradients problem and enables the training of deep networks. It showed that deep residual networks could be trained effectively, achieving improved accuracy on several benchmark datasets compared to previous state-of-the-art models.\n",
    "\n",
    "\n",
    "# References\n",
    "\n",
    "* Deep Residual Learning for Image Recognition: https://arxiv.org/abs/1512.03385\n",
    "* ResNet Explained :https://www.analyticsvidhya.com/blog/2023/02/deep-residual-learning-for-image-recognition-resnet-explained/\n",
    "* Pytorch ResNet implementation from Scratch: https://www.youtube.com/watch?v=DkNIBBBvcPs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f27a5882916995"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.570725441Z",
     "start_time": "2023-08-17T09:41:36.332775822Z"
    }
   },
   "id": "1d2ee0b57c9a37bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building Custom Dataset for Traffic signs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a48679057be113ce"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.613612633Z",
     "start_time": "2023-08-17T09:41:36.341500256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforming the Data ToTensor and Normalize it \n",
    "transforms = T.Compose([T.ToTensor(), T.Resize((225, 225)),\n",
    "                        T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class TSignsDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.root_dir, self.df.iloc[index, 7])  #the column of paths in df is 7\n",
    "        image = Image.open(image_path)\n",
    "        y_class = torch.tensor(self.df.iloc[index, 6])  #the column of ClsassId in df is 6\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.627993362Z",
     "start_time": "2023-08-17T09:41:36.368939715Z"
    }
   },
   "id": "53176df2a951af45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading The data into DataLoaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "445e19967ce0560"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def getDataloaders (batch_size, training_set, validation_set):\n",
    "    train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=False)\n",
    "    dataloaders = {'training': train_loader, 'validation': valid_loader}\n",
    "    return dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.633574152Z",
     "start_time": "2023-08-17T09:41:36.380562526Z"
    }
   },
   "id": "c411ee0a1e4aaf5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building The ResNet Model from scratch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66be533497751839"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generic Residual block "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3470164a9dbc2f68"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super().__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False, )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0,\n",
    "                               bias=False, )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.647898311Z",
     "start_time": "2023-08-17T09:41:36.393993571Z"
    }
   },
   "id": "e8e9662610b426ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generic implementation of ResNet Class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e22e5d631a85c037"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride, bias=False)\n",
    "                , nn.BatchNorm2d(out_channels * 4))\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = out_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.664663410Z",
     "start_time": "2023-08-17T09:41:36.463017779Z"
    }
   },
   "id": "33c447dff22ff95f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The ResNet: 3 levels of depth"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb695d3ad935a93e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def ResNet50(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet101(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet152(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.716511181Z",
     "start_time": "2023-08-17T09:41:36.463238231Z"
    }
   },
   "id": "8ed6c1f4f27502c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training The model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99cbcf9cba3ef1e8"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def Train(model, device, criterion, optimizer, num_epochs, batch_size, dataloaders, out_path):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        print(\"*\" * 10)\n",
    "\n",
    "        for x in [\"training\", \"validation\"]:\n",
    "            if x == \"training\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0\n",
    "\n",
    "            for data in dataloaders[x]:\n",
    "                img, y = data\n",
    "                img, y = img.to(device), y.to(device)\n",
    "                print(\"Image is cuda: \", img.is_cuda)\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(img)\n",
    "                loss = criterion(y_pred, y)\n",
    "                _, preds = torch.max(y_pred, dim=1)\n",
    "\n",
    "                if x == 'training':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_accuracy += torch.sum(preds == y.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[x])\n",
    "            epoch_acc = running_accuracy / len(dataloaders[x])\n",
    "\n",
    "            print('{} Loss: {:.4f} || Accuracy: {:.4f}'.format(x, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if x == 'validation' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "\n",
    "    # load best model weights\n",
    "    torch.save(model.state_dict(), out_path)\n",
    "    return print('Best validation Accuracy: {:4f}'.format(best_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:41:36.716809936Z",
     "start_time": "2023-08-17T09:41:36.504109178Z"
    }
   },
   "id": "5e8e8aa185a04294"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
