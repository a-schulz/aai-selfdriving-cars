{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02902c7b-e530-47e5-94c0-6e3f10227ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_utils as cu\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c9e9e6-d8d4-4b7a-86cc-58fd3f0898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 0: get images \n",
    "p, images = cu.get_images(\"/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/green\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f75ad51-17da-4cbf-9208-4b1682ce77cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 traffic light, 1: 640x640 2 traffic lights, 2: 640x640 1 traffic light, 3: 640x640 2 traffic lights, 4: 640x640 1 traffic light, 5: 640x640 2 traffic lights, 6: 640x640 1 traffic light, 1 bottle, 7: 640x640 (no detections), 8: 640x640 1 traffic light, 9: 640x640 2 traffic lights, 10: 640x640 2 persons, 2 cars, 1 motorcycle, 1 traffic light, 11: 640x640 1 traffic light, 12: 640x640 1 traffic light, 13: 640x640 1 person, 3 cars, 14: 640x640 (no detections), 15: 640x640 1 traffic light, 16: 640x640 6 persons, 6 cars, 1 motorcycle, 3 traffic lights, 17: 640x640 (no detections), 18: 640x640 1 traffic light, 19: 640x640 2 traffic lights, 20: 640x640 1 traffic light, 21: 640x640 1 traffic light, 22: 640x640 1 traffic light, 23: 640x640 1 traffic light, 1 refrigerator, 24: 640x640 2 traffic lights, 1 apple, 25: 640x640 1 person, 3 cars, 2 traffic lights, 26: 640x640 (no detections), 27: 640x640 1 traffic light, 28: 640x640 1 traffic light, 29: 640x640 1 traffic light, 30: 640x640 2 traffic lights, 31: 640x640 (no detections), 32: 640x640 (no detections), 33: 640x640 1 person, 1 car, 1 motorcycle, 34: 640x640 1 train, 1 traffic light, 35: 640x640 (no detections), 36: 640x640 1 person, 2 traffic lights, 1 teddy bear, 37: 640x640 2 traffic lights, 38: 640x640 1 traffic light, 1 clock, 39: 640x640 1 traffic light, 40: 640x640 1 tv, 41: 640x640 1 traffic light, 42: 640x640 2 traffic lights, 43: 640x640 3 persons, 1 truck, 2 traffic lights, 1 elephant, 44: 640x640 1 traffic light, 1 clock, 45: 640x640 1 traffic light, 46: 640x640 1 person, 2 traffic lights, 1 bottle, 47: 640x640 1 person, 1 traffic light, 48: 640x640 1 traffic light, 49: 640x640 (no detections), 50: 640x640 1 traffic light, 51: 640x640 1 truck, 1 traffic light, 52: 640x640 4 traffic lights, 53: 640x640 1 traffic light, 54: 640x640 1 traffic light, 55: 640x640 (no detections), 56: 640x640 1 person, 1 car, 57: 640x640 (no detections), 58: 640x640 1 person, 59: 640x640 1 bus, 1 train, 1 traffic light, 60: 640x640 2 traffic lights, 61: 640x640 2 apples, 62: 640x640 5 traffic lights, 63: 640x640 (no detections), 64: 640x640 2 persons, 4 cars, 65: 640x640 3 traffic lights, 66: 640x640 3 traffic lights, 67: 640x640 2 traffic lights, 1 chair, 68: 640x640 1 chair, 69: 640x640 1 traffic light, 70: 640x640 4 traffic lights, 71: 640x640 3 traffic lights, 72: 640x640 1 traffic light, 73: 640x640 2 persons, 2 cars, 74: 640x640 2 traffic lights, 75: 640x640 2 traffic lights, 76: 640x640 4 persons, 1 motorcycle, 5 traffic lights, 77: 640x640 1 traffic light, 78: 640x640 2 cars, 1 truck, 2 traffic lights, 79: 640x640 1 traffic light, 80: 640x640 1 traffic light, 81: 640x640 2 traffic lights, 1 bottle, 82: 640x640 4 traffic lights, 83: 640x640 2 traffic lights, 84: 640x640 4 persons, 3 cars, 1 motorcycle, 1 traffic light, 85: 640x640 2 traffic lights, 86: 640x640 (no detections), 87: 640x640 1 traffic light, 88: 640x640 1 traffic light, 89: 640x640 1 traffic light, 90: 640x640 1 car, 2 traffic lights, 91: 640x640 (no detections), 92: 640x640 3 traffic lights, 93: 640x640 3 traffic lights, 94: 640x640 (no detections), 95: 640x640 1 traffic light, 96: 640x640 1 traffic light, 97: 640x640 1 person, 3 traffic lights, 1 tv, 98: 640x640 1 traffic light, 99: 640x640 4 cars, 3 traffic lights, 10314.3ms\n",
      "Speed: 3.2ms preprocess, 103.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict3\u001b[0m\n",
      "86 labels saved to /home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict3/labels\n"
     ]
    }
   ],
   "source": [
    "# step 1: analyze images with yolo\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "results = model.predict(images, save=True, save_txt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3eb63051-f1d3-4aca-8dca-b8ad63120162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_list = [[1.0, 2.0, 3.0, 4.0], [1.2, 2.2, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [1.1, 2.1, 3.1, 4.1]]\\nthreshold = 0.2\\nfiltered_list = drop_similar_boxes(input_list, threshold)\\nprint(filtered_list)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo \n",
    "# drop similar boxes is requiered becaus some times yolo identify the same object with a different bounding box\n",
    "def drop_similar_boxes(input_list, threshold):\n",
    "    def are_elements_similar(elem1, elem2):\n",
    "        x1_diff = abs(elem1[0] - elem2[0])\n",
    "        y1_diff = abs(elem1[1] - elem2[1])\n",
    "        x2_diff = abs(elem1[2] - elem2[2])\n",
    "        y2_diff = abs(elem1[3] - elem2[3])\n",
    "        return x1_diff < threshold or y1_diff < threshold or x2_diff < threshold or y2_diff < threshold\n",
    "\n",
    "    unique_elements = []\n",
    "    for elem in input_list:\n",
    "        is_similar = False\n",
    "        for unique_elem in unique_elements:\n",
    "            if are_elements_similar(elem, unique_elem):\n",
    "                is_similar = True\n",
    "                break\n",
    "        if not is_similar:\n",
    "            unique_elements.append(elem)\n",
    "    return unique_elements\n",
    "\"\"\"\n",
    "input_list = [[1.0, 2.0, 3.0, 4.0], [1.2, 2.2, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [1.1, 2.1, 3.1, 4.1]]\n",
    "threshold = 0.2\n",
    "filtered_list = drop_similar_boxes(input_list, threshold)\n",
    "print(filtered_list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9e8ea2-5a0e-44b3-a58f-38075cfae35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_resize(images):\n",
    "    dia_len = [(i.shape[1]**2 + i.shape[2])**0.5 for i in images]\n",
    "    avr = int(np.average(dia_len))\n",
    "    for idx, i in enumerate(images):\n",
    "        i = cv2.resize(i, (avr,avr))\n",
    "        cv2.imwrite(\"/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/test_out/resize/\" + str(idx) + \".jpg\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3da4d2-a2d4-42fa-9c28-fd35bf7d8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: extract all traffic lights from all analyzed images and create for each an new image\n",
    "# Process results list\n",
    "out_path = '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/test_out/'\n",
    "image_name = 'traffic_light_green'\n",
    "file_type = '.jpg'\n",
    "\n",
    "counter = 0\n",
    "extracted_images = []\n",
    "for j, result in enumerate(results):\n",
    "    for i,c in enumerate(result.boxes.cls.numpy()):\n",
    "        # find traffic light boxes\n",
    "        points = result.boxes.xyxyn.numpy()[i]\n",
    "        if c == 9:\n",
    "            path = out_path + image_name + str(counter) + file_type\n",
    "            new_image = cu.extract_rectangle_from_image(images[j], points, save=False, output_path = path) \n",
    "            extracted_images.append(new_image)\n",
    "            counter += 1\n",
    "            \n",
    "# resize imgaes\n",
    "average_resize(extracted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "192c4596-623d-4408-a53c-d9e1f6a58155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fbac9ac-795b-4eb2-8836-2effd1132d50",
   "metadata": {},
   "source": [
    "# step 3: check images manually and label them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
