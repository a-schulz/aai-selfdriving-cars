{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02902c7b-e530-47e5-94c0-6e3f10227ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_utils as cu\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "labels = [\"green\", \"red\", \"yellow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1150d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load .env files\n",
    "load_dotenv()\n",
    "\n",
    "# Get environment variables\n",
    "dataset_dir = os.getenv('DATASET_DIR')\n",
    "ori_data_dir = os.path.join(dataset_dir, \"traffic_light\", \"original_data\")\n",
    "custom_data_dir = os.path.join(dataset_dir, \"traffic_light\", \"custom_data\")\n",
    "\n",
    "if not os.path.exists(ori_data_dir):\n",
    "    print(\"Error: No original data set\")\n",
    "\n",
    "if not os.path.exists(custom_data_dir):\n",
    "    os.mkdir(custom_data_dir)\n",
    "\n",
    "for l in labels:\n",
    "    label_dir = os.path.join(custom_data_dir, l)\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.mkdir(label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c9e9e6-d8d4-4b7a-86cc-58fd3f0898f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/green\n",
      "911\n",
      "0 traffic-light--1-_jpg.rf.3ae134bdb27867d6c1a6a311e7eb8831.jpg\n",
      "1 traffic-light--1-_jpg.rf.4a000eed21624b81d05ad71bc359e148.jpg\n",
      "2 traffic-light--1-_jpg.rf.daef3a72f098a087aac1799a1c29ca89.jpg\n",
      "3 traffic-light--10-_jpg.rf.322ccc6d4d307f5671d8edc784f02208.jpg\n",
      "break\n",
      "3\n",
      "['/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/green/traffic-light--1-_jpg.rf.3ae134bdb27867d6c1a6a311e7eb8831.jpg', '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/green/traffic-light--1-_jpg.rf.4a000eed21624b81d05ad71bc359e148.jpg', '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/green/traffic-light--1-_jpg.rf.daef3a72f098a087aac1799a1c29ca89.jpg']\n",
      "/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/green\n",
      "/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/red\n",
      "1194\n",
      "0 traffic-light--100-_jpg.rf.308fe0d060a70eadabf516a533bc7f3c.jpg\n",
      "1 traffic-light--1000-_jpg.rf.21b920a9abcec668bbe00eaa5bbc21b9.jpg\n",
      "2 traffic-light--1000-_jpg.rf.c4b0296d263502627f4a684a78c0a8ab.jpg\n",
      "3 traffic-light--1000-_jpg.rf.d28b2fea8ee2b80e92db42761e44c4df.jpg\n",
      "break\n",
      "3\n",
      "['/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/red/traffic-light--100-_jpg.rf.308fe0d060a70eadabf516a533bc7f3c.jpg', '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/red/traffic-light--1000-_jpg.rf.21b920a9abcec668bbe00eaa5bbc21b9.jpg', '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/red/traffic-light--1000-_jpg.rf.c4b0296d263502627f4a684a78c0a8ab.jpg']\n",
      "/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/red\n",
      "/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/yellow\n",
      "292\n",
      "0 traffic-light--101-_jpg.rf.2c911f388cf7395b27a6215712584484.jpg\n",
      "1 traffic-light--101-_jpg.rf.8628673f017f438bd5cd8e68d4259b73.jpg\n",
      "2 traffic-light--101-_jpg.rf.8c543917035e3a9f127697a20915b098.jpg\n",
      "3 traffic-light--104-_jpg.rf.2c4f5135a2f00a4c6738b2656b9e3217.jpg\n",
      "break\n",
      "3\n",
      "['/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/yellow/traffic-light--101-_jpg.rf.2c911f388cf7395b27a6215712584484.jpg', '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/yellow/traffic-light--101-_jpg.rf.8628673f017f438bd5cd8e68d4259b73.jpg', '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/yellow/traffic-light--101-_jpg.rf.8c543917035e3a9f127697a20915b098.jpg']\n",
      "/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/dataset/traffic_light/original_data/yellow\n"
     ]
    }
   ],
   "source": [
    "# step 0: get images \n",
    "img_dic = {}\n",
    "for l in labels: \n",
    "    paths, images = cu.get_images(os.path.join(ori_data_dir, l), 3)\n",
    "    print(paths)\n",
    "    print(os.path.join(ori_data_dir, l))\n",
    "    img_dic.update({l: images })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f75ad51-17da-4cbf-9208-4b1682ce77cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 apple, 1: 640x640 1 apple, 2: 640x640 (no detections), 454.5ms\n",
      "Speed: 5.7ms preprocess, 151.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30\u001b[0m\n",
      "2 labels saved to /home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30/labels\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic light, 1: 640x640 1 traffic light, 2: 640x640 1 traffic light, 696.7ms\n",
      "Speed: 5.3ms preprocess, 232.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30\u001b[0m\n",
      "3 labels saved to /home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30/labels\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic light, 1: 640x640 1 traffic light, 2: 640x640 1 traffic light, 586.0ms\n",
      "Speed: 3.5ms preprocess, 195.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30\u001b[0m\n",
      "3 labels saved to /home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30/labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# step 1: analyze images with yolo\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "res_dict = {}\n",
    "\n",
    "for l in labels:\n",
    "    print(l)\n",
    "    res = model.predict(img_dic[l], conf=0.3, save=True, save_txt = True)\n",
    "    print(type(res))\n",
    "    res_dict.update({l : res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb63051-f1d3-4aca-8dca-b8ad63120162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_list = [[1.0, 2.0, 3.0, 4.0], [1.2, 2.2, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [1.1, 2.1, 3.1, 4.1]]\\nthreshold = 0.2\\nfiltered_list = drop_similar_boxes(input_list, threshold)\\nprint(filtered_list)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo \n",
    "# drop similar boxes is requiered becaus some times yolo identify the same object with a different bounding box\n",
    "\"\"\"\n",
    "def drop_similar_boxes(input_list, threshold):\n",
    "    def are_elements_similar(elem1, elem2):\n",
    "        x1_diff = abs(elem1[0] - elem2[0])\n",
    "        y1_diff = abs(elem1[1] - elem2[1])\n",
    "        x2_diff = abs(elem1[2] - elem2[2])\n",
    "        y2_diff = abs(elem1[3] - elem2[3])\n",
    "        return x1_diff < threshold or y1_diff < threshold or x2_diff < threshold or y2_diff < threshold\n",
    "\n",
    "    unique_elements = []\n",
    "    for elem in input_list:\n",
    "        is_similar = False\n",
    "        for unique_elem in unique_elements:\n",
    "            if are_elements_similar(elem, unique_elem):\n",
    "                is_similar = True\n",
    "                break\n",
    "        if not is_similar:\n",
    "            unique_elements.append(elem)\n",
    "    return unique_elements\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "input_list = [[1.0, 2.0, 3.0, 4.0], [1.2, 2.2, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [1.1, 2.1, 3.1, 4.1]]\n",
    "threshold = 0.2\n",
    "filtered_list = drop_similar_boxes(input_list, threshold)\n",
    "print(filtered_list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9e8ea2-5a0e-44b3-a58f-38075cfae35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_resize(label, images):\n",
    "    print(\"type of images: \")\n",
    "    print(type(images[0]))\n",
    "    dia_len = [(i.shape[1]**2 + i.shape[2])**0.5 for i in images]\n",
    "    avr = int(np.average(dia_len))\n",
    "    for idx, i in enumerate(images):\n",
    "        print(\"hi\")\n",
    "        i = cv2.resize(i, (avr,avr))\n",
    "        #cv2.imwrite(os.path.join(custom_data_dir, label, str(idx), \".jpg\"), i) # not nessecary that label is in the name of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1d29deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "orig_img: array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)\n",
      "orig_shape: (416, 416)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30'\n",
      "speed: {'preprocess': 5.72355588277181, 'inference': 151.4862378438314, 'postprocess': 1.775185267130534}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "orig_img: array([[[27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        ...,\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27]],\n",
      "\n",
      "       [[27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        ...,\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27]],\n",
      "\n",
      "       [[27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        ...,\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        ...,\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27]],\n",
      "\n",
      "       [[27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        ...,\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27]],\n",
      "\n",
      "       [[27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        ...,\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27],\n",
      "        [27, 27, 27]]], dtype=uint8)\n",
      "orig_shape: (416, 416)\n",
      "path: 'image1.jpg'\n",
      "probs: None\n",
      "save_dir: '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30'\n",
      "speed: {'preprocess': 5.72355588277181, 'inference': 151.4862378438314, 'postprocess': 1.775185267130534}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "orig_img: array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8)\n",
      "orig_shape: (416, 416)\n",
      "path: 'image2.jpg'\n",
      "probs: None\n",
      "save_dir: '/home/jay/module/ai_app/self_driving_cars/aai-selfdriving-cars/runs/detect/predict30'\n",
      "speed: {'preprocess': 5.72355588277181, 'inference': 151.4862378438314, 'postprocess': 1.775185267130534}]\n"
     ]
    }
   ],
   "source": [
    "print(res_dict[\"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba3da4d2-a2d4-42fa-9c28-fd35bf7d8f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n",
      "red\n",
      "[[[ 55 182 107]\n",
      "  [ 49 184 106]\n",
      "  [ 34 168  95]\n",
      "  ...\n",
      "  [ 82  99  85]\n",
      "  [ 93 110  96]\n",
      "  [ 99 116 102]]\n",
      "\n",
      " [[ 63 189 113]\n",
      "  [ 60 195 115]\n",
      "  [ 56 190 114]\n",
      "  ...\n",
      "  [ 53  75  56]\n",
      "  [ 62  81  62]\n",
      "  [ 69  85  68]]\n",
      "\n",
      " [[ 54 179 100]\n",
      "  [ 52 183 102]\n",
      "  [ 64 194 117]\n",
      "  ...\n",
      "  [ 70 102  77]\n",
      "  [ 67  90  68]\n",
      "  [ 68  84  66]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 76 107 100]\n",
      "  [ 72  93  84]\n",
      "  [ 64  78  66]\n",
      "  ...\n",
      "  [ 99 117 100]\n",
      "  [101 117 100]\n",
      "  [101 117 100]]\n",
      "\n",
      " [[ 75 104  95]\n",
      "  [ 70  89  80]\n",
      "  [ 62  76  64]\n",
      "  ...\n",
      "  [ 98 117 100]\n",
      "  [ 99 117 100]\n",
      "  [ 99 117 100]]\n",
      "\n",
      " [[ 81 106  96]\n",
      "  [ 74  91  80]\n",
      "  [ 66  79  65]\n",
      "  ...\n",
      "  [ 98 117 100]\n",
      "  [ 98 117 100]\n",
      "  [ 99 117 100]]]\n",
      "[[[ 92 121 195]\n",
      "  [ 91 121 192]\n",
      "  [ 89 121 192]\n",
      "  ...\n",
      "  [142 140 140]\n",
      "  [158 155 141]\n",
      "  [157 152 127]]\n",
      "\n",
      " [[105 121 197]\n",
      "  [104 121 194]\n",
      "  [100 119 192]\n",
      "  ...\n",
      "  [169 181 191]\n",
      "  [192 203 200]\n",
      "  [202 212 196]]\n",
      "\n",
      " [[115 121 198]\n",
      "  [116 122 199]\n",
      "  [115 123 200]\n",
      "  ...\n",
      "  [174 193 208]\n",
      "  [193 210 213]\n",
      "  [204 220 213]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 83 102  59]\n",
      "  [ 66  90  42]\n",
      "  [ 78 108  55]\n",
      "  ...\n",
      "  [ 70  94  82]\n",
      "  [ 67  91  79]\n",
      "  [ 58  82  70]]\n",
      "\n",
      " [[ 85 103  62]\n",
      "  [ 65  88  43]\n",
      "  [ 77 106  56]\n",
      "  ...\n",
      "  [ 70  94  82]\n",
      "  [ 68  92  80]\n",
      "  [ 55  79  67]]\n",
      "\n",
      " [[ 90 109  70]\n",
      "  [ 69  93  51]\n",
      "  [ 56  85  39]\n",
      "  ...\n",
      "  [ 55  79  67]\n",
      "  [ 56  80  68]\n",
      "  [ 62  86  74]]]\n",
      "[[[ 39  53  47]\n",
      "  [ 47  57  51]\n",
      "  [ 51  61  55]\n",
      "  ...\n",
      "  [ 70  97  87]\n",
      "  [ 71 101  90]\n",
      "  [ 67  99  88]]\n",
      "\n",
      " [[ 40  53  45]\n",
      "  [ 46  59  51]\n",
      "  [ 48  61  53]\n",
      "  ...\n",
      "  [ 70  94  84]\n",
      "  [ 71  96  86]\n",
      "  [ 70  97  87]]\n",
      "\n",
      " [[ 38  51  43]\n",
      "  [ 44  57  49]\n",
      "  [ 45  58  50]\n",
      "  ...\n",
      "  [ 67  88  79]\n",
      "  [ 66  90  80]\n",
      "  [ 65  90  80]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[241 251 255]\n",
      "  [244 255 255]\n",
      "  [246 255 255]\n",
      "  ...\n",
      "  [255 255 213]\n",
      "  [235 244 194]\n",
      "  [223 238 187]]\n",
      "\n",
      " [[246 255 255]\n",
      "  [243 255 255]\n",
      "  [242 255 253]\n",
      "  ...\n",
      "  [254 255 210]\n",
      "  [240 255 203]\n",
      "  [231 252 197]]\n",
      "\n",
      " [[250 255 248]\n",
      "  [248 255 249]\n",
      "  [244 255 247]\n",
      "  ...\n",
      "  [235 247 197]\n",
      "  [225 244 195]\n",
      "  [228 251 199]]]\n",
      "yellow\n",
      "[[[102 188 134]\n",
      "  [ 93 175 122]\n",
      "  [ 89 169 116]\n",
      "  ...\n",
      "  [112 118 107]\n",
      "  [115 123 112]\n",
      "  [115 125 113]]\n",
      "\n",
      " [[ 82 171 115]\n",
      "  [ 91 178 122]\n",
      "  [105 189 134]\n",
      "  ...\n",
      "  [ 38  59  44]\n",
      "  [ 52  71  56]\n",
      "  [ 67  84  70]]\n",
      "\n",
      " [[ 92 186 127]\n",
      "  [104 196 137]\n",
      "  [118 208 149]\n",
      "  ...\n",
      "  [ 41  79  57]\n",
      "  [ 39  72  51]\n",
      "  [ 43  71  51]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[105 102  94]\n",
      "  [104 102  94]\n",
      "  [104 102  94]\n",
      "  ...\n",
      "  [ 94 118 100]\n",
      "  [ 94 118 100]\n",
      "  [ 94 118 100]]\n",
      "\n",
      " [[ 94  85  81]\n",
      "  [101  92  89]\n",
      "  [102  96  91]\n",
      "  ...\n",
      "  [ 94 118 100]\n",
      "  [ 94 118 100]\n",
      "  [ 94 118 100]]\n",
      "\n",
      " [[ 62  53  50]\n",
      "  [ 74  64  64]\n",
      "  [ 79  72  69]\n",
      "  ...\n",
      "  [ 92 118 100]\n",
      "  [ 92 118 100]\n",
      "  [ 92 118 100]]]\n",
      "[[[116 139 124]\n",
      "  [116 139 124]\n",
      "  [116 139 124]\n",
      "  ...\n",
      "  [122 137 129]\n",
      "  [124 138 127]\n",
      "  [125 139 128]]\n",
      "\n",
      " [[116 139 124]\n",
      "  [116 139 124]\n",
      "  [116 139 124]\n",
      "  ...\n",
      "  [119 139 127]\n",
      "  [119 139 127]\n",
      "  [122 139 128]]\n",
      "\n",
      " [[115 138 123]\n",
      "  [115 138 123]\n",
      "  [115 138 123]\n",
      "  ...\n",
      "  [115 139 127]\n",
      "  [115 139 127]\n",
      "  [116 141 127]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 90 147 102]\n",
      "  [ 83 136  93]\n",
      "  [ 82 132  90]\n",
      "  ...\n",
      "  [149 184 140]\n",
      "  [169 202 158]\n",
      "  [156 189 145]]\n",
      "\n",
      " [[102 191 135]\n",
      "  [102 186 132]\n",
      "  [109 187 134]\n",
      "  ...\n",
      "  [151 183 142]\n",
      "  [172 202 161]\n",
      "  [170 200 159]]\n",
      "\n",
      " [[ 85 194 132]\n",
      "  [ 87 190 129]\n",
      "  [ 95 189 130]\n",
      "  ...\n",
      "  [121 153 112]\n",
      "  [142 171 132]\n",
      "  [158 188 147]]]\n",
      "[[[133 162 139]\n",
      "  [133 162 139]\n",
      "  [132 161 138]\n",
      "  ...\n",
      "  [143 143 131]\n",
      "  [149 147 136]\n",
      "  [143 139 128]]\n",
      "\n",
      " [[133 163 138]\n",
      "  [133 163 138]\n",
      "  [132 162 137]\n",
      "  ...\n",
      "  [141 148 133]\n",
      "  [136 141 126]\n",
      "  [140 143 128]]\n",
      "\n",
      " [[131 165 135]\n",
      "  [133 164 137]\n",
      "  [132 163 136]\n",
      "  ...\n",
      "  [125 147 128]\n",
      "  [127 147 128]\n",
      "  [128 147 128]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[151 255 183]\n",
      "  [148 255 179]\n",
      "  [129 236 157]\n",
      "  ...\n",
      "  [123 241 158]\n",
      "  [129 245 162]\n",
      "  [136 252 169]]\n",
      "\n",
      " [[148 255 181]\n",
      "  [138 248 170]\n",
      "  [122 233 153]\n",
      "  ...\n",
      "  [131 251 170]\n",
      "  [150 255 185]\n",
      "  [140 252 174]]\n",
      "\n",
      " [[140 236 166]\n",
      "  [143 243 171]\n",
      "  [147 251 174]\n",
      "  ...\n",
      "  [126 249 169]\n",
      "  [152 255 193]\n",
      "  [143 255 180]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# resize imgaes\\nprint(extracted_dic[l])\\naverage_resize(l, extracted_dic[l])\\nout_path = os.path.join(custom_data_dir, l)\\nprint(out_path)\\ncu.write_images(extracted_dic[l], out_path, main_name=l)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2: extract all traffic lights from all analyzed images and create for each an new image\n",
    "\n",
    "# Process results list\n",
    "image_name = 'traffic_light_green'\n",
    "file_type = '.jpg'\n",
    "\n",
    "counter = 0\n",
    "extracted_dic = {}\n",
    "for l in labels:\n",
    "    print(l)\n",
    "    ex_images = [] # is an list because probably there are more traffic_lights objects in a picture\n",
    "    for j, result in enumerate(res_dict[l]):\n",
    "        for i,c in enumerate(result.boxes.cls.numpy()):\n",
    "            # find traffic light boxes\n",
    "\n",
    "            if c == 9:\n",
    "                points = result.boxes.xyxyn.numpy()[i]\n",
    "                extracted_image = cu.extract_rectangle_from_image(images[j], points) \n",
    "                ex_images.append(extracted_image)\n",
    "                print(extracted_image)\n",
    "                # res_dict[l][j] = extracted #\n",
    "                # print(type(res_dict[l][j]))\n",
    "                counter += 1\n",
    "    \n",
    "    extracted_dic.update({l : ex_images})\n",
    "\n",
    "\"\"\"\n",
    "# resize imgaes\n",
    "print(extracted_dic[l])\n",
    "average_resize(l, extracted_dic[l])\n",
    "out_path = os.path.join(custom_data_dir, l)\n",
    "print(out_path)\n",
    "cu.write_images(extracted_dic[l], out_path, main_name=l)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbac9ac-795b-4eb2-8836-2effd1132d50",
   "metadata": {},
   "source": [
    "# step 3: check images manually and label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0de74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49098ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
