{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02902c7b-e530-47e5-94c0-6e3f10227ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_utils as cu\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "labels = [\"green\", \"red\", \"yellow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1150d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load .env files\n",
    "load_dotenv()\n",
    "\n",
    "# Get environment variables\n",
    "dataset_dir = os.getenv('DATASET_DIR')\n",
    "ori_data_dir = os.getenv('TRAFFIC_LIGHT_ORIGINAL_DATA')\n",
    "custom_data_dir = os.getenv('TRAFFIC_LIGHT_CUSTOM_DATA')\n",
    "\n",
    "if not os.path.exists(ori_data_dir):\n",
    "    print(\"Error: No original data set\")\n",
    "\n",
    "if not os.path.exists(custom_data_dir):\n",
    "    os.mkdir(custom_data_dir)\n",
    "\n",
    "for l in labels:\n",
    "    label_dir = os.path.join(custom_data_dir, l)\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.mkdir(label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9e9e6-d8d4-4b7a-86cc-58fd3f0898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 0: get images \n",
    "img_dic = {}\n",
    "for l in labels: \n",
    "    paths, images = cu.get_images(os.path.join(ori_data_dir, l), 100)\n",
    "    print(paths)\n",
    "    print(os.path.join(ori_data_dir, l))\n",
    "    img_dic.update({l: images })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d29deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boxes(yolo_res, cls):\n",
    "    ex_boxes = []\n",
    "    for res in yolo_res:\n",
    "        for i, c in enumerate(res.boxes.cls.numpy()):\n",
    "            if c == cls:\n",
    "                points = res.boxes.xyxyn.numpy()[i]\n",
    "                ex_box = cu.extract_rectangle_from_image(cv2.cvtColor(res.orig_img, cv2.COLOR_BGR2RGB), points)\n",
    "                ex_boxes.append(ex_box)\n",
    "    return ex_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\") # test with sample images shows that, m is a good mid way between accuracy and run time\n",
    "res_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75ad51-17da-4cbf-9208-4b1682ce77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: analyze images and extract boxes with yolo\n",
    "for l in labels:\n",
    "    res = model.predict(img_dic[l], conf=0.3)\n",
    "    boxes = extract_boxes(res,9)\n",
    "    res_dict.update({l : boxes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e8ea2-5a0e-44b3-a58f-38075cfae35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_resize(res_dict):\n",
    "    #dia_len = [(i.shape[1]**2 + i.shape[2])**0.5 for i in images]\n",
    "    hights = []\n",
    "    widths = []\n",
    "    for l in res_dict:\n",
    "        hights += [i.shape[0] for i in res_dict[l]]\n",
    "        widths += [i.shape[1] for i in res_dict[l]]\n",
    "    #height, width = image.shape[:2]\n",
    "    avr_x = int(np.average(widths))\n",
    "    avr_y = int(np.average(hights))\n",
    "    for l in res_dict:\n",
    "        for idx, i in enumerate(res_dict[l]):\n",
    "            res_dict[l][idx] = cv2.resize(i, (avr_x,avr_y))\n",
    "        #cv2.imwrite(os.path.join(custom_data_dir, label, str(idx), \".jpg\"), i) # not nessecary that label is in the name of image\n",
    "    return res_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize all images to the same average hight and width \n",
    "res_dict = average_resize(res_dict) \n",
    "#i = average_resize(res_dict)\n",
    "#n = np.array(i[\"green\"])\n",
    "#print(n.shape)\n",
    "#len(n[1][2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save resized images in custom_data\n",
    "for l in labels:\n",
    "    path = os.path.join(custom_data_dir, l)\n",
    "    cu.write_images(res_dict[l], path, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4147d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31771c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(threshold = 0.6, directory = None, images = None):\n",
    "    if directory is not None:\n",
    "        # load pictures \n",
    "        _ , images = cu.get_images(directory)\n",
    "\n",
    "    # Erzeuge eine leere Liste zum Speichern der Tupel\n",
    "    similar_images = []\n",
    "    num_images = len(images)\n",
    "\n",
    "    # compare each picture\n",
    "    for i in range(num_images):\n",
    "        for j in range(i + 1, num_images):\n",
    "            # convert images into grayscale (ssim works only with that)\n",
    "            gray_image1 = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "            gray_image2 = cv2.cvtColor(images[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # calculate ssim value\n",
    "            similarity_score, _ = ssim(gray_image1, gray_image2, full=True)\n",
    "\n",
    "            # check if ssim is bigger than threshold to find most similar pictures\n",
    "            if similarity_score > threshold:\n",
    "                similar_images.append((i, j))\n",
    "\n",
    "    return np.array(similar_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16beb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_dic = {}\n",
    "sim_dic = {}\n",
    "for l in labels:\n",
    "    custom_cls_path = os.path.join(custom_data_dir, l)\n",
    "    _ , custom_images = cu.get_images(custom_cls_path)\n",
    "    cus_dic.update({l : custom_images})\n",
    "    s = find_similar(threshold=0.8, images=cus_dic[l])\n",
    "    sim_dic.update({l : s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fef90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_pairs(image_list, index_pairs):\n",
    "    current_pair_index = 0\n",
    "    num_pairs = len(index_pairs)\n",
    "\n",
    "    while current_pair_index < num_pairs:\n",
    "        image_indices = index_pairs[current_pair_index]\n",
    "        image1 = image_list[image_indices[0]]\n",
    "        image2 = image_list[image_indices[1]]\n",
    "\n",
    "        combined_image = cv2.hconcat([image1, image2])\n",
    "\n",
    "        cv2.imshow(\"Image Pair\" + str(index_pairs[current_pair_index]) , combined_image)\n",
    "        key = cv2.waitKey(0)\n",
    "        current_pair_index += 1\n",
    "\n",
    "        #if key == ord(\"1\"):\n",
    "        #elif key == ord(\"2\"):\n",
    "        #    cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eaedb28",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cls = \"green\"\n",
    "show_image_pairs(cus_dic[cls], sim_dic[cls]) # TODO openCV crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in labels:\n",
    "    print(len(sim_dic[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbac9ac-795b-4eb2-8836-2effd1132d50",
   "metadata": {},
   "source": [
    "# step 3: check images manually and label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e4246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(res_dict[\"green\"][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
